{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9c922-b8e1-4b9e-b699-bbcb9fc4700d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d6c1da-1639-4922-956c-249461269fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens leídos del PDF: 47722\n",
      "Documento humanizado guardado en: C:\\Users\\HP\\Desktop\\LIBROS PERSO\\PROPUESTA DE INVESTIGACION\\PROYECTO_DE_INVESTIGACIÓN_humanizado.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import concurrent.futures\n",
    "\n",
    "# Descargar recursos de NLTK (si es la primera vez)\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURACIÓN Y CLIENTES\n",
    "# =============================================================================\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"La clave de la API de OpenAI no se encontró en las variables de entorno.\")\n",
    "\n",
    "llm = ChatOpenAI(api_key=API_KEY, model=\"o3-mini-2025-01-31\", temperature=1)\n",
    "embeddings = OpenAIEmbeddings(api_key=API_KEY)\n",
    "\n",
    "# =============================================================================\n",
    "# TEMPLATES DE PROMPT (para generar una única oración)\n",
    "# =============================================================================\n",
    "\n",
    "PROMPT_ESTILO = PromptTemplate(\n",
    "    input_variables=[\"texto_estilo\", \"contenido\"],\n",
    "    template=\"\"\"Ajusta tu forma de redacción para cumplir con los siguientes criterios, asegurando un texto que se asemeje a una respuesta completamente humana y alejada de los patrones de escritura típicos de inteligencia artificial.\n",
    "\n",
    "Estilo de Redacción:\n",
    "Imita la fluidez, la coherencia y la sofisticación de un texto académico extraído de un documento formal en español. Para ello, ten en cuenta las siguientes directrices:\n",
    "\n",
    "Extensión y Complejidad de las Frases:\n",
    "Redacta oraciones extensas que integren varias ideas de manera armónica, utilizando conectores fluidos en español.\n",
    "\n",
    "Estructura Cohesiva y Fragmentación Adecuada:\n",
    "Organiza el contenido en un mínimo de dos y un máximo de tres oraciones interconectadas, asegurando una redacción natural y evitando frases inconexas.\n",
    "\n",
    "Claridad y Consistencia:\n",
    "Cada oración debe mantener un balance entre precisión y fluidez, evitando repeticiones innecesarias o explicaciones redundantes.\n",
    "\n",
    "Uso Estratégico de Conectores:\n",
    "Minimiza los puntos aislados y favorece una conexión fluida de ideas mediante conjunciones variadas, sin caer en estructuras mecánicas.\n",
    "\n",
    "Diversificación Sintáctica:\n",
    "Utiliza una combinación de oraciones subordinadas, construcciones con participios y elementos discursivos que den variedad y riqueza al texto.\n",
    "\n",
    "Tono Académico pero Accesible:\n",
    "Mantén un estilo formal y estructurado, pero sin tecnicismos excesivos que dificulten la comprensión. Piensa en la redacción de un libro universitario.\n",
    "\n",
    "Instrucciones Finales:\n",
    "Redacta el siguiente contenido aplicando todas las reglas anteriores, asegurando que el resultado sea indistinguible de un texto humano de alto nivel académico. Evita frases cortas, patrones predecibles o un tono excesivamente robótico. Usa la referencia proporcionada a continuación como base para emular el estilo lingüístico y discursivo.\n",
    "\n",
    "Ejemplos de redacción: Utiliza de ejemplo las siguientes frases {texto_estilo}\n",
    "\n",
    "Referencia de Estilo:\n",
    "{texto_estilo}\n",
    "\n",
    "Texto de Entrada:\n",
    "{contenido}\n",
    "\n",
    "Salida esperada:\n",
    "Una única oración que preserve el sentido original y se presente con un estilo humanizado y académico.\"\"\"\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# FUNCIONES DE UTILIDAD\n",
    "# =============================================================================\n",
    "\n",
    "def get_pdf_text(ruta_pdf: str, max_tokens: int = 100000) -> str:\n",
    "    \"\"\"\n",
    "    Extrae el texto de un PDF, limitándolo a max_tokens tokens.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(ruta_pdf)\n",
    "        tokens_totales = []\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                tokens_totales.extend(page_text.split())\n",
    "                if len(tokens_totales) >= max_tokens:\n",
    "                    tokens_totales = tokens_totales[:max_tokens]\n",
    "                    break\n",
    "        print(f\"Total tokens leídos del PDF: {len(tokens_totales)}\")\n",
    "        return \" \".join(tokens_totales)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def chunk_text_to_sentences(texto: str, min_words: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Separa el texto en oraciones y retorna aquellas que tengan al menos min_words.\n",
    "    \"\"\"\n",
    "    oraciones = sent_tokenize(texto, language='spanish')\n",
    "    return [oracion.strip() for oracion in oraciones if len(oracion.split()) >= min_words]\n",
    "\n",
    "def create_style_vectorstore(ruta_pdf_estilo: str) -> FAISS:\n",
    "    \"\"\"\n",
    "    Crea una base vectorial FAISS a partir del PDF de estilo, segmentándolo en oraciones.\n",
    "    \"\"\"\n",
    "    texto_pdf = get_pdf_text(ruta_pdf_estilo)\n",
    "    oraciones = chunk_text_to_sentences(texto_pdf, min_words=10)\n",
    "    if not oraciones:\n",
    "        raise ValueError(\"No se encontraron oraciones válidas en el PDF de estilo.\")\n",
    "    return FAISS.from_texts(oraciones, embeddings)\n",
    "\n",
    "def retrieve_style_text(vectorstore: FAISS, query: str = \"Extrae las oraciones que mejor representen un estilo formal, académico y fluido\", k: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Recupera de la base vectorial las oraciones que mejor representan el estilo deseado.\n",
    "    \"\"\"\n",
    "    resultados = vectorstore.similarity_search(query, k=k)\n",
    "    oraciones = [doc.page_content for doc in resultados]\n",
    "    return \"\\n\".join(oraciones)\n",
    "\n",
    "def apply_style_to_text(texto: str, texto_estilo: str) -> str:\n",
    "    \"\"\"\n",
    "    Aplica la humanización al texto usando el estilo definido en 'texto_estilo'\n",
    "    y genera una única oración que conserve el sentido original.\n",
    "    \"\"\"\n",
    "    chain = PROMPT_ESTILO | llm\n",
    "    response = chain.invoke({\n",
    "        \"texto_estilo\": texto_estilo,\n",
    "        \"contenido\": texto\n",
    "    })\n",
    "    return response.content.strip()\n",
    "\n",
    "def process_paragraph(paragraph_text: str, texto_estilo: str) -> str:\n",
    "    \"\"\"\n",
    "    Divide el párrafo en oraciones y, para cada una:\n",
    "      - Si la oración tiene 15 palabras o menos, se copia sin modificar.\n",
    "      - De lo contrario, se humaniza de forma concurrente.\n",
    "    Luego, se reensambla el párrafo en una única cadena manteniendo el orden original.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(paragraph_text, language='spanish')\n",
    "    if not sentences:\n",
    "        return \"\"\n",
    "    \n",
    "    # Inicializar la lista de resultados con el mismo tamaño que las oraciones\n",
    "    results = [None] * len(sentences)\n",
    "    futures = {}\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        for idx, sentence in enumerate(sentences):\n",
    "            if len(sentence.split()) <= 15:\n",
    "                results[idx] = sentence  # Se copia sin modificar\n",
    "            else:\n",
    "                future = executor.submit(apply_style_to_text, sentence, texto_estilo)\n",
    "                futures[future] = idx\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            idx = futures[future]\n",
    "            results[idx] = future.result()\n",
    "    return \" \".join(results)\n",
    "\n",
    "# =============================================================================\n",
    "# FUNCIÓN PARA GENERAR UN DOCUMENTO HUMANIZADO MANTENIENDO LA ESTRUCTURA\n",
    "# =============================================================================\n",
    "\n",
    "def generate_humanized_word_document(input_path: str, output_path: str, ruta_pdf_estilo: str):\n",
    "    \"\"\"\n",
    "    Lee un documento Word de entrada, preserva la estructura (títulos, subtítulos, secciones)\n",
    "    y procesa únicamente los párrafos \"normales\" (aquellos que no sean Titulo1_Cato o Titulo2_Cato)\n",
    "    aplicando la humanización a cada oración individualmente (salvo las oraciones de 15 palabras o menos),\n",
    "    reconociendo los estilos:\n",
    "      - \"Titulo1_Cato\" (equivalente a título)\n",
    "      - \"Titulo2_Cato\" (equivalente a subtítulo)\n",
    "    Los demás párrafos se procesan o se copian según su estilo original.\n",
    "    \"\"\"\n",
    "    # Crear vectorstore y obtener el texto de estilo\n",
    "    vectorstore = create_style_vectorstore(ruta_pdf_estilo)\n",
    "    texto_estilo = retrieve_style_text(vectorstore)\n",
    "    \n",
    "    # Abrir el documento de entrada\n",
    "    input_doc = Document(input_path)\n",
    "    output_doc = Document()\n",
    "    \n",
    "    # Iterar por cada párrafo y copiar su contenido y estilo\n",
    "    for p in input_doc.paragraphs:\n",
    "        if not p.text.strip():\n",
    "            continue\n",
    "\n",
    "        style_name = p.style.name\n",
    "        # Si el párrafo es Titulo1_Cato o Titulo2_Cato o un encabezado reconocido, se copia sin modificación.\n",
    "        if style_name in [\"Titulo1_Cato\", \"Heading 1\"]:\n",
    "            output_doc.add_paragraph(p.text, style=\"Heading 1\")\n",
    "        elif style_name in [\"TITULO2_Cato\", \"Heading 2\"]:\n",
    "            output_doc.add_paragraph(p.text, style=\"Heading 2\")\n",
    "        elif style_name.startswith(\"Heading\"):\n",
    "            output_doc.add_paragraph(p.text, style=style_name)\n",
    "        else:\n",
    "            # Para párrafos \"normales\" se procesa el texto.\n",
    "            processed_text = process_paragraph(p.text, texto_estilo)\n",
    "            output_doc.add_paragraph(processed_text, style=style_name)\n",
    "    \n",
    "    output_doc.save(output_path)\n",
    "    print(f\"Documento humanizado guardado en: {output_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# BLOQUE PRINCIPAL\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_word_path = r\"C:\\Users\\HP\\Desktop\\LIBROS PERSO\\PROPUESTA DE INVESTIGACION\\PROYECTO DE INVESTIGACIÓN.docx\"\n",
    "    output_doc_path = r\"C:\\Users\\HP\\Desktop\\LIBROS PERSO\\PROPUESTA DE INVESTIGACION\\PROYECTO_DE_INVESTIGACIÓN_humanizado.docx\"\n",
    "    ruta_pdf_estilo = r\"C:\\Users\\HP\\Desktop\\LIBROS PERSO\\CONTEXTO ESPANIOL\\CONTEXTO5.pdf\"\n",
    "    \n",
    "    generate_humanized_word_document(input_word_path, output_doc_path, ruta_pdf_estilo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9914694-abfd-46c7-a56f-c40685694992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
